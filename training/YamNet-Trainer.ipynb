{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkiuHZZwhDcp",
        "outputId": "80110478-beb4-4ba3-8923-ef731ef1a450"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfGDDx33lDJc",
        "outputId": "4d2c0e54-2238-4c4e-a5c9-8a4175fcb930"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow tensorflow_hub librosa scikit-learn matplotlib seaborn joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UI6CtL22rAKO"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'librosa'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Us-fAlqrvBM",
        "outputId": "897b048d-6107-459a-d92b-c0725179475c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading YAMNet model...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'hub' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Load YAMNet model from TensorFlow Hub\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading YAMNet model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m yamnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/yamnet/1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYAMNet loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hub' is not defined"
          ]
        }
      ],
      "source": [
        "# Step 1: Load YAMNet model from TensorFlow Hub\n",
        "print(\"Loading YAMNet model...\")\n",
        "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "print(\"YAMNet loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndoK6uQyryBX"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define function to extract YAMNet embeddings from an audio file\n",
        "def extract_yamnet_embedding(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Loads an audio file, resamples it to target_sr, and extracts the mean YAMNet embedding.\n",
        "    \"\"\"\n",
        "    waveform, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
        "    waveform = waveform.astype(np.float32)\n",
        "    scores, embeddings, spectrogram = yamnet_model(waveform)\n",
        "    mean_embedding = np.mean(embeddings.numpy(), axis=0)\n",
        "    return mean_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXBhN5OGr2D2",
        "outputId": "973203b7-c60d-4e8e-b038-62c880390867"
      },
      "outputs": [],
      "source": [
        "data_dir = '/home/ankit/WindowsFuneral/Hackathons/KU-HACKFEST-2025/acoustic-system/LoRa-Net/Forest_Datasets'\n",
        "audio_extensions = ('.wav', '.mp3')\n",
        "\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "# Directly iterate through sound class folders\n",
        "for subfolder in os.listdir(data_dir):\n",
        "    subfolder_path = os.path.join(data_dir, subfolder)\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        for file in os.listdir(subfolder_path):\n",
        "            if file.lower().endswith(audio_extensions):\n",
        "                file_paths.append(os.path.join(subfolder_path, file))\n",
        "                labels.append(subfolder)  # Use folder name as label\n",
        "\n",
        "print(f\"Total audio files found: {len(file_paths)}\")\n",
        "print(f\"Unique sub-labels: {len(set(labels))} -> {set(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ9C_1bHsImR",
        "outputId": "601e36e3-4ae3-4203-dbf7-0b333bb2bbdf"
      },
      "outputs": [],
      "source": [
        "# Step 4: Extract embeddings for all audio files (this may take time)\n",
        "print(\"Extracting YAMNet embeddings for all audio files...\")\n",
        "embeddings = []\n",
        "failed_files = []\n",
        "for fp in file_paths:\n",
        "    try:\n",
        "        emb = extract_yamnet_embedding(fp)\n",
        "        embeddings.append(emb)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {fp}: {e}\")\n",
        "        failed_files.append(fp)\n",
        "\n",
        "embeddings = np.array(embeddings)\n",
        "print(f\"Extracted embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "# Remove failed files from labels\n",
        "if failed_files:\n",
        "    print(f\"Removing {len(failed_files)} failed files from labels.\")\n",
        "    labels = [label for fp, label in zip(file_paths, labels) if fp not in failed_files]\n",
        "\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQIKCNULsJ63",
        "outputId": "7c605706-5f7f-458d-90df-0cdf3b60e571"
      },
      "outputs": [],
      "source": [
        "# Step 5: Encode labels to one-hot vectors\n",
        "label_binarizer = LabelBinarizer()\n",
        "one_hot_labels = label_binarizer.fit_transform(labels)\n",
        "class_names = label_binarizer.classes_\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"One-hot labels shape: {one_hot_labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzGQDz__sMGa",
        "outputId": "6b7fa56d-b893-409c-ba18-e3a58b1248b0"
      },
      "outputs": [],
      "source": [
        "# Step 6: Split dataset into train and test sets (stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    embeddings, one_hot_labels, test_size=0.2, random_state=42, stratify=one_hot_labels)\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "jQSSuG93sRNP",
        "outputId": "8de27c1f-ae4a-49db-ff55-a51410b0f290"
      },
      "outputs": [],
      "source": [
        "# Step 7: Build Keras classifier model with softmax output\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(1024,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKi4iUHyzeSZ",
        "outputId": "c00b5cc4-fc28-40f6-845d-b7cbe2b65bb1"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Assuming y_train are integer labels of shape (n_samples,)\n",
        "# Need to use the original labels before one-hot encoding for compute_class_weight\n",
        "# Assuming 'labels' variable contains the original string labels corresponding to the training data\n",
        "# We need to select the labels corresponding to the training split.\n",
        "# Since train_test_split was stratified on the one-hot labels, we can use the indices\n",
        "# to get the corresponding original labels. However, a simpler way is to use the original\n",
        "# 'labels' array and split it with the same random_state and stratify settings.\n",
        "\n",
        "# Re-split the original labels to get the training labels\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming the original 'labels' variable is still available from Step 3\n",
        "# If not, you would need to reconstruct or save it earlier.\n",
        "# Let's assume 'labels' from cell zXBhN5OGr2D2 is available.\n",
        "\n",
        "# Since the split in cell HzGQDz__sMGa was stratified on one_hot_labels,\n",
        "# we can perform the same split on the original 'labels' array to get y_train_original.\n",
        "# This ensures the correct correspondence between X_train and the original labels.\n",
        "X_train_dummy, X_test_dummy, y_train_original, y_test_original = train_test_split(\n",
        "    embeddings, labels, test_size=0.2, random_state=42, stratify=one_hot_labels)\n",
        "\n",
        "\n",
        "classes = np.unique(y_train_original)\n",
        "weights = class_weight.compute_class_weight('balanced', classes=classes, y=y_train_original)\n",
        "class_weight_dict = dict(zip(classes, weights))\n",
        "\n",
        "print(\"Class weights calculated:\")\n",
        "for cls, weight in class_weight_dict.items():\n",
        "    print(f\"  {cls}: {weight:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhZXkwP8sTkx",
        "outputId": "1fd5bcc2-3604-431e-fea3-81fb26200db0"
      },
      "outputs": [],
      "source": [
        "# Step 8: Train the model\n",
        "print(\"Training the classifier...\")\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=30,\n",
        "                    batch_size=32,\n",
        "                    class_weight=class_weight_dict,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euqB01NosVVs",
        "outputId": "26fe2559-880c-48fe-b205-260120bb4256"
      },
      "outputs": [],
      "source": [
        "# Step 9: Evaluate the model on the test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred_classes = y_pred_probs.argmax(axis=1)\n",
        "y_true_classes = y_test.argmax(axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "yneVpibSsZUJ",
        "outputId": "3fdeead3-ec5e-478c-debd-c6baf636be61"
      },
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5LHWkXdsbPn",
        "outputId": "799f150d-7f13-43db-aacf-7e8cf19ba691"
      },
      "outputs": [],
      "source": [
        "# Step 10: Save the trained model and label binarizer\n",
        "model_save_path = '/content/multi_class_audio_classifier.h5'\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to: {model_save_path}\")\n",
        "\n",
        "label_binarizer_path = '/content/label_binarizer.pkl'\n",
        "joblib.dump(label_binarizer, label_binarizer_path)\n",
        "print(f\"Label binarizer saved to: {label_binarizer_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xi79bQ3sdcs"
      },
      "outputs": [],
      "source": [
        "# Step 11: Function to predict sub-label on new audio file\n",
        "# def predict_audio_file(file_path, yamnet_model, keras_model, label_binarizer_obj, target_sr=16000):\n",
        "#     \"\"\"\n",
        "#     Predict the sub-label of a given audio file.\n",
        "#     \"\"\"\n",
        "#     waveform, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
        "#     waveform = waveform.astype(np.float32)\n",
        "#     scores, embeddings, spectrogram = yamnet_model(waveform)\n",
        "#     mean_embedding = np.mean(embeddings.numpy(), axis=0).reshape(1, -1)\n",
        "\n",
        "#     probs = keras_model.predict(mean_embedding)[0]\n",
        "#     pred_index = np.argmax(probs)\n",
        "#     pred_label = label_binarizer_obj.classes_[pred_index]\n",
        "#     confidence = probs[pred_index]\n",
        "\n",
        "#     print(f\"Predicted sub-label: {pred_label} with confidence {confidence:.3f}\")\n",
        "#     return pred_label, confidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y7Nb9tU8gY6"
      },
      "source": [
        "## batch_predict_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv7b21gm1UsP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def aggregate_probabilities_over_clip(file_path, yamnet_model, keras_model, label_binarizer,\n",
        "                                      window_size=2.0, hop_size=1.0, sr=16000):\n",
        "    \"\"\"\n",
        "    For a given audio file, compute softmax probabilities per sliding window,\n",
        "    aggregate over entire clip, and return average probabilities per class.\n",
        "    \"\"\"\n",
        "    waveform, _ = librosa.load(file_path, sr=sr, mono=True)\n",
        "    waveform = waveform.astype(np.float32)\n",
        "\n",
        "    window_samples = int(window_size * sr)\n",
        "    hop_samples = int(hop_size * sr)\n",
        "\n",
        "    num_windows = max(1, (len(waveform) - window_samples) // hop_samples + 1)\n",
        "\n",
        "    prob_sums = np.zeros(len(label_binarizer.classes_))\n",
        "\n",
        "    for i in range(num_windows):\n",
        "        start_sample = i * hop_samples\n",
        "        end_sample = start_sample + window_samples\n",
        "        window_waveform = waveform[start_sample:end_sample]\n",
        "\n",
        "        if len(window_waveform) < window_samples:\n",
        "            window_waveform = np.pad(window_waveform, (0, window_samples - len(window_waveform)))\n",
        "\n",
        "        scores, embeddings, _ = yamnet_model(window_waveform)\n",
        "        mean_embedding = np.mean(embeddings.numpy(), axis=0).reshape(1, -1)\n",
        "\n",
        "        probs = keras_model.predict(mean_embedding)[0]\n",
        "        prob_sums += probs\n",
        "\n",
        "    avg_probs = prob_sums / num_windows\n",
        "    percentages = avg_probs * 100\n",
        "    return percentages\n",
        "\n",
        "def plot_sound_distribution(percentages, class_names, file_name):\n",
        "    \"\"\"\n",
        "    Plot a bar chart of sound class percentages for a single audio file.\n",
        "    \"\"\"\n",
        "    sorted_indices = np.argsort(percentages)[::-1]\n",
        "    sorted_labels = class_names[sorted_indices]\n",
        "    sorted_percentages = percentages[sorted_indices]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(sorted_labels, sorted_percentages, color='skyblue')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ylabel('Percentage (%)')\n",
        "    plt.title(f'Sound Class Distribution for {file_name}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def batch_process_folder(test_folder, yamnet_model, keras_model, label_binarizer):\n",
        "    \"\"\"\n",
        "    Process all audio files in a folder, aggregate probabilities, and plot distributions.\n",
        "    \"\"\"\n",
        "    audio_extensions = ('.wav', '.mp3', '.flac', '.ogg', '.m4a')\n",
        "    for root, _, files in os.walk(test_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(audio_extensions):\n",
        "                file_path = os.path.join(root, file)\n",
        "                print(f\"\\nProcessing file: {file}\")\n",
        "                percentages = aggregate_probabilities_over_clip(file_path, yamnet_model, keras_model, label_binarizer)\n",
        "                for label, pct in zip(label_binarizer.classes_, percentages):\n",
        "                    print(f\"{label}: {pct:.2f}%\")\n",
        "                plot_sound_distribution(percentages, label_binarizer.classes_, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mVcNYyAA2Cdq",
        "outputId": "c812d228-c755-4b4a-f1d8-db4925f3f2dd"
      },
      "outputs": [],
      "source": [
        "# Usage example:\n",
        "test_folder_path = '/content/drive/MyDrive/testme'  # Your test folder path\n",
        "batch_process_folder(test_folder_path, yamnet_model, model, label_binarizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPjFbxsw8xKZ"
      },
      "source": [
        "## batch_process_folder_with_unknown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cx9fgjX2Dte"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def aggregate_probabilities_with_unknown(file_path, yamnet_model, keras_model, label_binarizer,\n",
        "#                                          window_size=2.0, hop_size=1.0, sr=16000, unknown_threshold=0.4):\n",
        "#     waveform, _ = librosa.load(file_path, sr=sr, mono=True)\n",
        "#     waveform = waveform.astype(np.float32)\n",
        "\n",
        "#     window_samples = int(window_size * sr)\n",
        "#     hop_samples = int(hop_size * sr)\n",
        "\n",
        "#     num_windows = max(1, (len(waveform) - window_samples) // hop_samples + 1)\n",
        "\n",
        "#     prob_sums = np.zeros(len(label_binarizer.classes_))\n",
        "\n",
        "#     for i in range(num_windows):\n",
        "#         start_sample = i * hop_samples\n",
        "#         end_sample = start_sample + window_samples\n",
        "#         window_waveform = waveform[start_sample:end_sample]\n",
        "\n",
        "#         if len(window_waveform) < window_samples:\n",
        "#             window_waveform = np.pad(window_waveform, (0, window_samples - len(window_waveform)))\n",
        "\n",
        "#         scores, embeddings, _ = yamnet_model(window_waveform)\n",
        "#         mean_embedding = np.mean(embeddings.numpy(), axis=0).reshape(1, -1)\n",
        "\n",
        "#         probs = keras_model.predict(mean_embedding)[0]\n",
        "#         prob_sums += probs\n",
        "\n",
        "#     avg_probs = prob_sums / num_windows\n",
        "\n",
        "#     max_prob = np.max(avg_probs)\n",
        "#     unknown_prob = 0.0\n",
        "#     if max_prob < unknown_threshold:\n",
        "#         unknown_prob = 1.0 - np.sum(avg_probs)\n",
        "#         # Clip unknown_prob to be non-negative (in case sum(avg_probs) > 1 due to numerical issues)\n",
        "#         unknown_prob = max(0.0, unknown_prob)\n",
        "\n",
        "#     # Prepare final classes and percentages including unknown\n",
        "#     final_classes = list(label_binarizer.classes_) + ['unknown']\n",
        "#     final_percentages = list(avg_probs * 100) + [unknown_prob * 100]\n",
        "\n",
        "#     return final_classes, final_percentages\n",
        "\n",
        "# def plot_distribution_with_unknown(classes, percentages, file_name):\n",
        "#     sorted_indices = np.argsort(percentages)[::-1]\n",
        "#     sorted_labels = np.array(classes)[sorted_indices]\n",
        "#     sorted_percentages = np.array(percentages)[sorted_indices]\n",
        "\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "#     plt.bar(sorted_labels, sorted_percentages, color='coral')\n",
        "#     plt.xticks(rotation=45, ha='right')\n",
        "#     plt.ylabel('Percentage (%)')\n",
        "#     plt.title(f'Sound Class Distribution with Unknown for {file_name}')\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# def batch_process_folder_with_unknown(test_folder, yamnet_model, keras_model, label_binarizer,\n",
        "#                                       unknown_threshold=0.4):\n",
        "#     audio_extensions = ('.wav', '.mp3', '.flac', '.ogg', '.m4a')\n",
        "#     for root, _, files in os.walk(test_folder):\n",
        "#         for file in files:\n",
        "#             if file.lower().endswith(audio_extensions):\n",
        "#                 file_path = os.path.join(root, file)\n",
        "#                 print(f\"\\nProcessing file: {file}\")\n",
        "#                 classes, percentages = aggregate_probabilities_with_unknown(\n",
        "#                     file_path, yamnet_model, keras_model, label_binarizer,\n",
        "#                     unknown_threshold=unknown_threshold)\n",
        "#                 for label, pct in zip(classes, percentages):\n",
        "#                     print(f\"{label}: {pct:.2f}%\")\n",
        "#                 plot_distribution_with_unknown(classes, percentages, file)\n",
        "\n",
        "# # Usage example:\n",
        "# test_folder_path = '/content/drive/MyDrive/testme'\n",
        "# batch_process_folder_with_unknown(test_folder_path, yamnet_model, model, label_binarizer, unknown_threshold=0.4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SbRf2Qc87jA"
      },
      "source": [
        "## batch_process_folder_with_confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROWhlp2qR_ia"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import librosa\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def aggregate_probabilities_with_confidence_filter(file_path, yamnet_model, keras_model, label_binarizer,\n",
        "#                                                   window_size=2.0, hop_size=1.0, sr=16000,\n",
        "#                                                   confidence_threshold=0.6, unknown_threshold=0.4):\n",
        "#     \"\"\"\n",
        "#     Aggregate softmax probabilities over sliding windows in an audio file,\n",
        "#     only including windows where max class probability >= confidence_threshold.\n",
        "#     Assign residual probability to 'unknown' class if confidence is low.\n",
        "#     \"\"\"\n",
        "#     waveform, _ = librosa.load(file_path, sr=sr, mono=True)\n",
        "#     waveform = waveform.astype(np.float32)\n",
        "\n",
        "#     window_samples = int(window_size * sr)\n",
        "#     hop_samples = int(hop_size * sr)\n",
        "\n",
        "#     num_windows = max(1, (len(waveform) - window_samples) // hop_samples + 1)\n",
        "\n",
        "#     prob_sums = np.zeros(len(label_binarizer.classes_))\n",
        "#     confident_window_count = 0\n",
        "\n",
        "#     for i in range(num_windows):\n",
        "#         start_sample = i * hop_samples\n",
        "#         end_sample = start_sample + window_samples\n",
        "#         window_waveform = waveform[start_sample:end_sample]\n",
        "\n",
        "#         if len(window_waveform) < window_samples:\n",
        "#             window_waveform = np.pad(window_waveform, (0, window_samples - len(window_waveform)))\n",
        "\n",
        "#         scores, embeddings, _ = yamnet_model(window_waveform)\n",
        "#         mean_embedding = np.mean(embeddings.numpy(), axis=0).reshape(1, -1)\n",
        "\n",
        "#         probs = keras_model.predict(mean_embedding)[0]\n",
        "#         max_prob = np.max(probs)\n",
        "\n",
        "#         if max_prob >= confidence_threshold:\n",
        "#             prob_sums += probs\n",
        "#             confident_window_count += 1\n",
        "#         else:\n",
        "#             # Window considered uncertain; ignored in known class aggregation\n",
        "#             pass\n",
        "\n",
        "#     if confident_window_count > 0:\n",
        "#         avg_probs = prob_sums / confident_window_count\n",
        "#     else:\n",
        "#         avg_probs = np.zeros(len(label_binarizer.classes_))\n",
        "\n",
        "#     unknown_prob = 0.0\n",
        "#     # If too few confident windows or max avg prob low, assign unknown prob\n",
        "#     if confident_window_count < num_windows or np.max(avg_probs) < unknown_threshold:\n",
        "#         unknown_prob = 1.0 - np.sum(avg_probs)\n",
        "#         unknown_prob = max(0.0, unknown_prob)\n",
        "\n",
        "#     final_classes = list(label_binarizer.classes_) + ['unknown']\n",
        "#     final_percentages = list(avg_probs * 100) + [unknown_prob * 100]\n",
        "\n",
        "#     return final_classes, final_percentages\n",
        "\n",
        "# def plot_distribution_with_unknown(classes, percentages, file_name):\n",
        "#     \"\"\"\n",
        "#     Plot a bar chart of sound class percentages including unknown class.\n",
        "#     \"\"\"\n",
        "#     sorted_indices = np.argsort(percentages)[::-1]\n",
        "#     sorted_labels = np.array(classes)[sorted_indices]\n",
        "#     sorted_percentages = np.array(percentages)[sorted_indices]\n",
        "\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "#     plt.bar(sorted_labels, sorted_percentages, color='mediumseagreen')\n",
        "#     plt.xticks(rotation=45, ha='right')\n",
        "#     plt.ylabel('Percentage (%)')\n",
        "#     plt.title(f'Sound Class Distribution with Unknown for {file_name}')\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# def batch_process_folder_with_confidence(test_folder, yamnet_model, keras_model, label_binarizer,\n",
        "#                                          confidence_threshold=0.6, unknown_threshold=0.4):\n",
        "#     \"\"\"\n",
        "#     Process all audio files in a folder with confidence filtering and plot distributions.\n",
        "#     \"\"\"\n",
        "#     audio_extensions = ('.wav', '.mp3', '.flac', '.ogg', '.m4a')\n",
        "#     for root, _, files in os.walk(test_folder):\n",
        "#         for file in files:\n",
        "#             if file.lower().endswith(audio_extensions):\n",
        "#                 file_path = os.path.join(root, file)\n",
        "#                 print(f\"\\nProcessing file: {file}\")\n",
        "#                 classes, percentages = aggregate_probabilities_with_confidence_filter(\n",
        "#                     file_path, yamnet_model, keras_model, label_binarizer,\n",
        "#                     confidence_threshold=confidence_threshold,\n",
        "#                     unknown_threshold=unknown_threshold)\n",
        "#                 for label, pct in zip(classes, percentages):\n",
        "#                     print(f\"{label}: {pct:.2f}%\")\n",
        "#                 plot_distribution_with_unknown(classes, percentages, file)\n",
        "\n",
        "# # Usage example:\n",
        "# test_folder_path = '/content/drive/MyDrive/testme'  # Update to your test folder path\n",
        "# batch_process_folder_with_confidence(test_folder_path, yamnet_model, model, label_binarizer,\n",
        "#                                      confidence_threshold=0.15, unknown_threshold=0.4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ahfe38ntaF48",
        "outputId": "9b2a51aa-e83b-4cbe-9271-6225593e453c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def aggregate_probabilities_with_confidence_filter(file_path, yamnet_model, keras_model, label_binarizer,\n",
        "                                                  window_size=2.0, hop_size=1.0, sr=16000,\n",
        "                                                  confidence_threshold=0.6):\n",
        "    \"\"\"\n",
        "    Aggregate softmax probabilities over sliding windows in an audio file,\n",
        "    only including windows where max class probability >= confidence_threshold.\n",
        "    Does NOT assign residual probability to 'unknown' class.\n",
        "    \"\"\"\n",
        "    waveform, _ = librosa.load(file_path, sr=sr, mono=True)\n",
        "    waveform = waveform.astype(np.float32)\n",
        "\n",
        "    window_samples = int(window_size * sr)\n",
        "    hop_samples = int(hop_size * sr)\n",
        "\n",
        "    num_windows = max(1, (len(waveform) - window_samples) // hop_samples + 1)\n",
        "\n",
        "    prob_sums = np.zeros(len(label_binarizer.classes_))\n",
        "    confident_window_count = 0\n",
        "\n",
        "    for i in range(num_windows):\n",
        "        start_sample = i * hop_samples\n",
        "        end_sample = start_sample + window_samples\n",
        "        window_waveform = waveform[start_sample:end_sample]\n",
        "\n",
        "        if len(window_waveform) < window_samples:\n",
        "            window_waveform = np.pad(window_waveform, (0, window_samples - len(window_waveform)))\n",
        "\n",
        "        scores, embeddings, _ = yamnet_model(window_waveform)\n",
        "        mean_embedding = np.mean(embeddings.numpy(), axis=0).reshape(1, -1)\n",
        "\n",
        "        probs = keras_model.predict(mean_embedding)[0]\n",
        "        max_prob = np.max(probs)\n",
        "\n",
        "        if max_prob >= confidence_threshold:\n",
        "            prob_sums += probs\n",
        "            confident_window_count += 1\n",
        "        else:\n",
        "            # Window considered uncertain; ignored in known class aggregation\n",
        "            pass\n",
        "\n",
        "    if confident_window_count > 0:\n",
        "        avg_probs = prob_sums / confident_window_count\n",
        "    else:\n",
        "        avg_probs = np.zeros(len(label_binarizer.classes_))\n",
        "\n",
        "    final_classes = list(label_binarizer.classes_)  # No 'unknown' class added\n",
        "    final_percentages = list(avg_probs * 100)       # No unknown probability added\n",
        "\n",
        "    return final_classes, final_percentages\n",
        "\n",
        "\n",
        "def plot_distribution_with_unknown(classes, percentages, file_name):\n",
        "    \"\"\"\n",
        "    Plot a bar chart of sound class percentages.\n",
        "    \"\"\"\n",
        "    sorted_indices = np.argsort(percentages)[::-1]\n",
        "    sorted_labels = np.array(classes)[sorted_indices]\n",
        "    sorted_percentages = np.array(percentages)[sorted_indices]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(sorted_labels, sorted_percentages, color='mediumseagreen')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ylabel('Percentage (%)')\n",
        "    plt.title(f'Sound Class Distribution for {file_name}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def batch_process_folder_with_confidence(test_folder, yamnet_model, keras_model, label_binarizer,\n",
        "                                         confidence_threshold=0.6):\n",
        "    \"\"\"\n",
        "    Process all audio files in a folder with confidence filtering and plot distributions.\n",
        "    \"\"\"\n",
        "    audio_extensions = ('.wav', '.mp3', '.flac', '.ogg', '.m4a')\n",
        "    for root, _, files in os.walk(test_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(audio_extensions):\n",
        "                file_path = os.path.join(root, file)\n",
        "                print(f\"\\nProcessing file: {file}\")\n",
        "                classes, percentages = aggregate_probabilities_with_confidence_filter(\n",
        "                    file_path, yamnet_model, keras_model, label_binarizer,\n",
        "                    confidence_threshold=confidence_threshold)\n",
        "                for label, pct in zip(classes, percentages):\n",
        "                    print(f\"{label}: {pct:.2f}%\")\n",
        "                plot_distribution_with_unknown(classes, percentages, file)\n",
        "\n",
        "\n",
        "# Usage example:\n",
        "test_folder_path = '/content/drive/MyDrive/testme'  # Update to your test folder path\n",
        "batch_process_folder_with_confidence(test_folder_path, yamnet_model, model, label_binarizer,\n",
        "                                     confidence_threshold=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDD0_rPmVVNn"
      },
      "source": [
        "## Check the plot 5 second"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lMk_RPU3Sl8g",
        "outputId": "6cb52b41-6458-4f79-ea96-9623e9a5f4c7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def predict_per_5s_clip(file_path, yamnet_model, keras_model, label_binarizer, clip_duration=5.0, sr=16000):\n",
        "    \"\"\"\n",
        "    Splits the audio file into consecutive non-overlapping 5-second clips,\n",
        "    predicts softmax probabilities for each clip,\n",
        "    and returns a list of probability arrays (one per clip).\n",
        "    \"\"\"\n",
        "    waveform, _ = librosa.load(file_path, sr=sr, mono=True)\n",
        "    waveform = waveform.astype(np.float32)\n",
        "\n",
        "    clip_samples = int(clip_duration * sr)\n",
        "    total_samples = len(waveform)\n",
        "    num_clips = total_samples // clip_samples\n",
        "\n",
        "    clip_probabilities = []\n",
        "\n",
        "    for i in range(num_clips):\n",
        "        start = i * clip_samples\n",
        "        end = start + clip_samples\n",
        "        clip_waveform = waveform[start:end]\n",
        "\n",
        "        # Extract YAMNet embeddings\n",
        "        scores, embeddings, _ = yamnet_model(clip_waveform)\n",
        "        mean_embedding = np.mean(embeddings.numpy(), axis=0).reshape(1, -1)\n",
        "\n",
        "        # Predict softmax probabilities\n",
        "        probs = keras_model.predict(mean_embedding)[0]\n",
        "        clip_probabilities.append(probs)\n",
        "\n",
        "    return clip_probabilities\n",
        "\n",
        "def plot_grouped_bar_seaborn(clip_probabilities, class_names, clip_duration=5.0):\n",
        "    \"\"\"\n",
        "    Creates a grouped bar chart using Seaborn.\n",
        "    Each group is a 5-second clip (C1, C2, ...),\n",
        "    each bar is a class probability.\n",
        "    \"\"\"\n",
        "    # Prepare data for seaborn in long format\n",
        "    data = []\n",
        "    for clip_idx, probs in enumerate(clip_probabilities):\n",
        "        clip_label = f'C{clip_idx+1} ({clip_idx*clip_duration:.0f}-{(clip_idx+1)*clip_duration:.0f}s)'\n",
        "        for class_idx, class_name in enumerate(class_names):\n",
        "            data.append({\n",
        "                'Clip': clip_label,\n",
        "                'Sound Class': class_name,\n",
        "                'Probability': probs[class_idx]\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(14, 7))\n",
        "\n",
        "    # Create grouped barplot\n",
        "    ax = sns.barplot(x='Clip', y='Probability', hue='Sound Class', data=df, ci=None)\n",
        "\n",
        "    ax.set_title('Sound Class Probabilities per 5-Second Clip')\n",
        "    ax.set_ylabel('Probability')\n",
        "    ax.set_xlabel('5-Second Clips')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend(title='Sound Class', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def batch_process_and_plot_seaborn(test_folder, yamnet_model, keras_model, label_binarizer, clip_duration=5.0, sr=16000):\n",
        "    \"\"\"\n",
        "    Process all audio files in a folder, predict per 5-second clip,\n",
        "    and plot grouped bar charts per file using Seaborn.\n",
        "    \"\"\"\n",
        "    audio_extensions = ('.wav', '.mp3', '.flac', '.ogg', '.m4a')\n",
        "\n",
        "    for root, _, files in os.walk(test_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(audio_extensions):\n",
        "                file_path = os.path.join(root, file)\n",
        "                print(f\"\\nProcessing file: {file}\")\n",
        "                clip_probs = predict_per_5s_clip(file_path, yamnet_model, keras_model, label_binarizer, clip_duration, sr)\n",
        "                if clip_probs:\n",
        "                    plot_grouped_bar_seaborn(clip_probs, label_binarizer.classes_, clip_duration)\n",
        "                else:\n",
        "                    print(\"Audio too short for segmentation.\")\n",
        "\n",
        "# Usage example:\n",
        "test_folder = '/content/drive/MyDrive/testme'\n",
        "batch_process_and_plot_seaborn(test_folder, yamnet_model, model, label_binarizer, clip_duration=5.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uz0PkKr96Aj"
      },
      "source": [
        "## Single inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-ewt-DUV2Jd"
      },
      "outputs": [],
      "source": [
        "def single_inference_with_confidence(\n",
        "    file_path, yamnet_model, keras_model, label_binarizer,\n",
        "    confidence_threshold=0.6\n",
        "):\n",
        "    \"\"\"\n",
        "    Process a single audio file with confidence filtering and plot the distribution.\n",
        "    \"\"\"\n",
        "    classes, percentages = aggregate_probabilities_with_confidence_filter(\n",
        "        file_path, yamnet_model, keras_model, label_binarizer,\n",
        "        confidence_threshold=confidence_threshold\n",
        "    )\n",
        "    print(f\"\\nProcessing file: {os.path.basename(file_path)}\")\n",
        "    for label, pct in zip(classes, percentages):\n",
        "        print(f\"{label}: {pct:.2f}%\")\n",
        "    plot_distribution_with_unknown(classes, percentages, os.path.basename(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GuuPU-WB4kya",
        "outputId": "ff8bd959-4ae9-46f4-b12b-a27c948fa2dc"
      },
      "outputs": [],
      "source": [
        "# Usage example:\n",
        "audio_file_path = '/content/drive/MyDrive/testme/testing.mpeg'  # Update with your file path\n",
        "single_inference_with_confidence(\n",
        "    audio_file_path, yamnet_model, model, label_binarizer,\n",
        "    confidence_threshold=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDo_7ybi5kEU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "loranet",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
